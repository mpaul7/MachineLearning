{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fdfaac",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "- Build a machine learning pipeline\n",
    "\n",
    "#### ML Pipeline\n",
    "- There are some standard workflows in machine learning projects that can be automated. \n",
    "- In scikit-learn **Pipeline** utility can help to cleary define and automate these workflows. \n",
    "\n",
    "#### What is Pipeline utility?\n",
    "- It allows linear sequence of of data transforms to be chained together in a modeling process that can be evaluated. \n",
    "\n",
    "###  [input] - [wf-1] - [wf-2] - [wf-3] - [wf-n] - [predictions]\n",
    "\n",
    "- Pipelines help prevent data leakage\n",
    "- For example, data preparation like standardization is constrained to each fold of cross validation procedure. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c411e",
   "metadata": {},
   "source": [
    "#### Load Python libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef36ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e26b8",
   "metadata": {},
   "source": [
    "#### Check Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d91a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first 20 rows of the dataset\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394e671",
   "metadata": {},
   "source": [
    "### Separate input and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee4b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test \n",
    "data_array = data.values\n",
    "X = data_array[:,0:8]\n",
    "y = data_array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2e225",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Data Preparation and Modeling Pipeline</span>\n",
    "\n",
    "- Create a pipeline to prepare the dataset using Standard Scaler on the entire training dataset before traing the model.\n",
    "### [input] - [standardize] - [classifier] - [predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline worksflows\n",
    "estimator1 = [] # list instantiation\n",
    "estimator1.append(('standardize', StandardScaler()))\n",
    "estimator1.append(('clf', DecisionTreeClassifier()))\n",
    "\n",
    "# instantiate Pipeline class with pipeline workflows\n",
    "pipe1 = Pipeline(estimator1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192fd26",
   "metadata": {},
   "source": [
    "## Evaluate Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KFold class with number of splits\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "# cross validation on Kfolds \n",
    "results = cross_val_score(pipe1, X, y, cv=kfold, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41dca6d",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy per fold\\n======================================\")\n",
    "for i in range(len(results)):\n",
    "    print(\"Accuracy - Fold-{}  -> {}\".format(i, results[i]))\n",
    "\n",
    "print(\"\\nAverage accuracy\\n=====================================\")\n",
    "print(\"Accuracy - {}\".format(results.mean()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180d7e6",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "- Statistical tests can be used to select those features have strongest relationshio with the output variable.\n",
    "- scikit-learn provides the **SelectKBest** class to do feature selection\n",
    "- It can be used with a suite of different statistical tests to select a specific number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44032c14",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- Use Pima Indians Diabetes dataset and **select best 4 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e27bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already have X and y from Pima indian dataset\n",
    "\n",
    "# Load Python library for feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import operator\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "# Feature selection (k)\n",
    "select_feat = SelectKBest(score_func=chi2, k=4)\n",
    "select_feat_fit = select_feat.fit(X, y)\n",
    "\n",
    "# Summarize Scores\n",
    "feat_scores = select_feat_fit.scores_\n",
    "\n",
    "\n",
    "# Summarize selected features\n",
    "feat_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "feature_score_map = dict(zip(feat_names, feat_scores))\n",
    "sorted_feature_score = dict(sorted(feature_score_map.items(), key=operator.itemgetter(1), reverse=True))\n",
    "for k, v in sorted_feature_score.items():\n",
    "    print(k, \":\", v)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470370b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd21fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature set\n",
    "features = select_feat_fit.transform(X)\n",
    "print(f'\\n{features[0:5, :]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ce428",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Data Preparation, Feature Extraction and Modeling Pipeline</span>\n",
    "\n",
    "- Create a pipeline to extract features and classfication model.\n",
    "### [input] - [normalizer] - [feature-selection] - [Classifier] - [Predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline workflows\n",
    "estimator2 = []\n",
    "estimator2.append(('minmaxscaler', MinMaxScaler(feature_range=(0, 1))))\n",
    "estimator2.append(('select_best', SelectKBest(score_func=chi2, k=4)))\n",
    "estimator2.append(('clf', DecisionTreeClassifier()))\n",
    "\n",
    "# instantiate Pipeline class with pipeline workflows\n",
    "pipe2 = Pipeline(estimator2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c9ec8",
   "metadata": {},
   "source": [
    "## Evaluate Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KFold class with number of splits\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "# cross validation on Kfolds \n",
    "results = cross_val_score(pipe2, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d396fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy per fold\\n======================================\")\n",
    "for i in range(len(results)):\n",
    "    print(\"Accuracy - Fold-{}  -> {}\".format(i, results[i]))\n",
    "\n",
    "print(\"\\nAverage accuracy\\n=====================================\")\n",
    "print(\"Accuracy - {}\".format(results.mean()*100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
