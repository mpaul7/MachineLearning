{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632d1466",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "- Load data set \n",
    "- Normalize data\n",
    "- Standardize data\n",
    "\n",
    "#### Need for Pre-processing\n",
    "- Different algorithms make differnt assumptions about your data and may require different transforms. \n",
    "- On the otherhand, some algorithms can deliver better results without pre-processing.\n",
    "\n",
    "- General idea here is that iterate over bunch of data transforms and algorithms and check the performance, and select the appropriate transform and algorithm....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7a642",
   "metadata": {},
   "source": [
    "#### Load Python libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da5798",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe876c",
   "metadata": {},
   "source": [
    "#### Check Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0548d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first 20 rows of the dataset\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3a573",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Normalize Data</span>\n",
    "\n",
    "- Data attributes may have varying scales. \n",
    "- In this situation, many ML algorithms may not perform well.  \n",
    "- To get better results we have to recale data.\n",
    "- This is referred to as normalization and attributes are often rescaled into the range between 0 and 1. \n",
    "- Rescale data can be implemented using scikit-learn **MinMaxScaler** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python library MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4354062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate array into input and output components\n",
    "data_array = data.values\n",
    "X = data_array[:,0:8]\n",
    "y = data_array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46b08",
   "metadata": {},
   "source": [
    "### Descriptive Statistics data before Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Statistical properties of each attribute\n",
    "X_data = pd.DataFrame(data=X)\n",
    "print(X_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c6f70",
   "metadata": {},
   "source": [
    "\n",
    "#### Normalize Data using MinMaxScaler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "# instantiate MinMaxScaler class\n",
    "scaler = MinMaxScaler(feature_range=(0, 5))\n",
    "normalizedX = scaler.fit_transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3) # set output precision to three decimal places\n",
    "# print first 5 rows\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df570e",
   "metadata": {},
   "source": [
    "### Descriptive Statistics data after Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93908b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized_data = pd.DataFrame(data=normalizedX)\n",
    "print(X_normalized_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814195ea",
   "metadata": {},
   "source": [
    "#### Above output shows that after rescaling all of the values are in the range between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d4489",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Standardize Data</span>\n",
    "\n",
    "- Data having Gussian distributions may have differing means and standard deviations\n",
    "- **Standardization** is a useful technique to transform attributes to a mean of **0** and a standard deviation of **1**.\n",
    "- It transforms data to a standard Gaussian distribution \n",
    "- It is most suitable for techniques that assume a Gaussian distribution in the input variables, such as\n",
    "    - linear regression, \n",
    "    - logistic regression and  \n",
    "- Standardize data can be implemnted using scikit-learn with the **StandardScaler** class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7a2b2",
   "metadata": {},
   "source": [
    "### Density distribution of data before Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Statistical properties of each attribute\n",
    "X_data = pd.DataFrame(data=X)### Density distribution of data after Standardization\n",
    "X_data.plot(kind='density', subplots=True, layout=(3,3), sharex=False, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860d3d4",
   "metadata": {},
   "source": [
    "\n",
    "#### Standardize Data using StandardScaler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Library StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate StandardScaler class and fit on data \n",
    "scaler = StandardScaler().fit(X)\n",
    "standardizedX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)# set output precision to three decimal places\n",
    "# print first 5 rows\n",
    "print(standardizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7cc309",
   "metadata": {},
   "source": [
    "### Density distribution of data after Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00828efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Statistical properties of each attribute\n",
    "X_standardized_data = pd.DataFrame(data=standardizedX)\n",
    "X_standardized_data.plot(kind='density', subplots=True, layout=(3,3), sharex=False, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433dd4c5",
   "metadata": {},
   "source": [
    "#### Above output shows that after Standardizing mean is 0 and standard deviation is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b81202",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- Normalization - ? \n",
    "- Standardization - ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b6dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
